{
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [],
      "dockerImageVersionId": 30673,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Semitic_preprocessor"
      ],
      "metadata": {
        "id": "6Wb04YC9w9MR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "class Semitic_preprocessor:\n",
        "  @staticmethod\n",
        "  def string_vectorizer(string, vocabulary, max_len):\n",
        "    empty = Semitic_preprocessor.empty_matrix(max_len, vocabulary)\n",
        "    for i,l in enumerate(string):\n",
        "      empty[i, vocabulary.index(l)] = 1\n",
        "    return empty\n",
        "\n",
        "\n",
        "  @staticmethod\n",
        "  def create_vocabulary(list_of_words):\n",
        "    vocabulary = set(''.join(list_of_words))\n",
        "    vocabulary = sorted([i for i in vocabulary])\n",
        "    return vocabulary\n",
        "\n",
        "\n",
        "  @staticmethod\n",
        "  def empty_matrix(max_len, vocabulary):\n",
        "    array = []\n",
        "    for i in range(max_len):\n",
        "      array.append([0] * len(vocabulary))\n",
        "    return np.array(array)\n",
        "\n",
        "  @staticmethod\n",
        "  def generate_report(model, model_history):\n",
        "    pass"
      ],
      "metadata": {
        "id": "EdcN-v88hmQA",
        "execution": {
          "iopub.status.busy": "2024-03-25T09:26:42.271158Z",
          "iopub.execute_input": "2024-03-25T09:26:42.271819Z",
          "iopub.status.idle": "2024-03-25T09:26:42.281019Z",
          "shell.execute_reply.started": "2024-03-25T09:26:42.271775Z",
          "shell.execute_reply": "2024-03-25T09:26:42.279797Z"
        },
        "trusted": true
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data"
      ],
      "metadata": {
        "id": "hV3Y-K9XxCix"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/delmedigo88/Semitic.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J8pWaUjbw9Wx",
        "outputId": "01140129-8a94-4e5d-badf-375339ad0b74",
        "execution": {
          "iopub.status.busy": "2024-03-25T09:26:45.639275Z",
          "iopub.execute_input": "2024-03-25T09:26:45.639890Z",
          "iopub.status.idle": "2024-03-25T09:26:48.379243Z",
          "shell.execute_reply.started": "2024-03-25T09:26:45.639858Z",
          "shell.execute_reply": "2024-03-25T09:26:48.377876Z"
        },
        "trusted": true
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'Semitic' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load all neccessary packages\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras import models, layers\n",
        "from sklearn.preprocessing import OneHotEncoder"
      ],
      "metadata": {
        "id": "z_Fg-SgyVpL8"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define type of model\n",
        "\n",
        "model_type = 'third_char'\n",
        "\n",
        "if model_type == 'first_char':\n",
        "  letter_index = 0\n",
        "elif model_type == 'second_char':\n",
        "  letter_index = 1\n",
        "else:\n",
        "  letter_index = 2\n",
        "max_word_length = 8"
      ],
      "metadata": {
        "id": "TJCpyrTRUxOc"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read txt files directly from raw file on Github\n",
        "\n",
        "df = pd.read_csv(\"Semitic/data/arabic_words_clean.csv\",\n",
        "                 # separate by # the word and root\n",
        "                 encoding_errors= \"ignore\")\n",
        "\n",
        "df_2side=df.sample(frac=.05, random_state=1)\n",
        "df.drop(df_2side.index, axis=0, inplace=True)\n",
        "df_2side.to_excel('word-root-table_side.xlsx', index=False)"
      ],
      "metadata": {
        "id": "BwkRkIUliCkT",
        "execution": {
          "iopub.status.busy": "2024-03-25T09:27:14.337778Z",
          "iopub.execute_input": "2024-03-25T09:27:14.338205Z",
          "iopub.status.idle": "2024-03-25T09:27:15.547041Z",
          "shell.execute_reply.started": "2024-03-25T09:27:14.338176Z",
          "shell.execute_reply": "2024-03-25T09:27:15.545785Z"
        },
        "trusted": true
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## One Letter Prediction"
      ],
      "metadata": {
        "id": "mME0ggL1ZF4N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# text data to matrix representation\n",
        "\n",
        "sp = Semitic_preprocessor()\n",
        "\n",
        "arabic_vocabulary = sp.create_vocabulary(df['word'])\n",
        "test_df = df.copy()\n",
        "\n",
        "test_df['word_as_matrix'] = test_df['word'].apply(lambda x: sp.string_vectorizer(x, arabic_vocabulary, max_word_length))\n",
        "test_df['first_letter'] = test_df['root'].apply(lambda x: x[letter_index])\n",
        "test_df['letter_as_matrix'] = test_df['first_letter'].apply(lambda x: sp.string_vectorizer(x, arabic_vocabulary, 1))\n",
        "\n",
        "X = np.stack(test_df['word_as_matrix'].to_numpy())\n",
        "y = np.stack(test_df['letter_as_matrix'].to_numpy())\n",
        "\n",
        "print(f' The shape of X is: {X.shape}')\n",
        "print(f' The shape of y is: {y.shape}')"
      ],
      "metadata": {
        "id": "271b2edJyri0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4b1d9fc-a272-450b-e8a5-b8d90a0036ee",
        "execution": {
          "iopub.status.busy": "2024-03-25T09:32:43.863759Z",
          "iopub.execute_input": "2024-03-25T09:32:43.864193Z",
          "iopub.status.idle": "2024-03-25T09:33:16.206871Z",
          "shell.execute_reply.started": "2024-03-25T09:32:43.864158Z",
          "shell.execute_reply": "2024-03-25T09:33:16.205661Z"
        },
        "trusted": true
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " The shape of X is: (838490, 8, 36)\n",
            " The shape of y is: (838490, 1, 36)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# define hyper-parameters\n",
        "\n",
        "hyper_param = dict(num_epochs = 10,\n",
        "                   loss_func ='mean_squared_error',\n",
        "                   lr = .001, batch_size= 64, test_size = .15,\n",
        "                   activation_func = 'relu', output_activation = 'linear',\n",
        "                   validation_split = .15,\n",
        "                   random_state = 42)\n",
        "\n",
        "# Split the data into training and testing| sets\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
        "                                                    test_size = hyper_param['test_size'],\n",
        "                                                    random_state= hyper_param['random_state'])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-25T10:12:06.400497Z",
          "iopub.execute_input": "2024-03-25T10:12:06.401571Z",
          "iopub.status.idle": "2024-03-25T10:12:06.407848Z",
          "shell.execute_reply.started": "2024-03-25T10:12:06.401518Z",
          "shell.execute_reply": "2024-03-25T10:12:06.406121Z"
        },
        "trusted": true,
        "id": "VEcTfNciGSJW"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# build model's architechture\n",
        "mlp_model = models.Sequential([\n",
        "\n",
        "    layers.Flatten(input_shape=(X.shape[1], X.shape[2])),  # Flatten the 3D input\n",
        "    layers.Dense(256, activation= hyper_param['activation_func']),\n",
        "    layers.Dense(128, activation=hyper_param['activation_func']),\n",
        "    layers.Dense(64, activation=hyper_param['activation_func']),\n",
        "    layers.Dense(32, activation=hyper_param['activation_func']),\n",
        "    layers.Dense(1 * X.shape[2], activation=hyper_param['output_activation']),\n",
        "    layers.Reshape((1, X.shape[2]))\n",
        "\n",
        "])\n",
        "\n",
        "# define optimizer\n",
        "\n",
        "adam_optimizer = tf.keras.optimizers.Adam(learning_rate=hyper_param['lr'])\n",
        "\n",
        "# compile the model\n",
        "\n",
        "mlp_model.compile(optimizer = adam_optimizer,\n",
        "                  loss= hyper_param['loss_func'],\n",
        "                  metrics=['Accuracy'])"
      ],
      "metadata": {
        "id": "jiwOzcHlHBTy"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the model\n",
        "\n",
        "mlp_model_logs = mlp_model.fit(X_train, y_train,\n",
        "                                                 epochs = hyper_param['num_epochs'],\n",
        "                                                 batch_size= hyper_param['batch_size'],\n",
        "                                                 validation_split= hyper_param['validation_split'])\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "\n",
        "loss, accuracy = mlp_model.evaluate(X_test, y_test)\n",
        "print(f'Test Loss: {loss}, Test Accuracy: {accuracy}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SOOCxq7ZWTd7",
        "outputId": "2953895b-0bb8-4734-fa4a-55f8590ec4ff"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "9466/9466 [==============================] - 52s 5ms/step - loss: 0.0039 - Accuracy: 0.9047 - val_loss: 0.0026 - val_Accuracy: 0.9289\n",
            "Epoch 2/10\n",
            "9466/9466 [==============================] - 54s 6ms/step - loss: 0.0017 - Accuracy: 0.9602 - val_loss: 0.0014 - val_Accuracy: 0.9691\n",
            "Epoch 3/10\n",
            "9466/9466 [==============================] - 54s 6ms/step - loss: 0.0011 - Accuracy: 0.9754 - val_loss: 0.0012 - val_Accuracy: 0.9745\n",
            "Epoch 4/10\n",
            "9466/9466 [==============================] - 48s 5ms/step - loss: 9.3652e-04 - Accuracy: 0.9799 - val_loss: 0.0010 - val_Accuracy: 0.9775\n",
            "Epoch 5/10\n",
            "9466/9466 [==============================] - 49s 5ms/step - loss: 8.0260e-04 - Accuracy: 0.9830 - val_loss: 9.3437e-04 - val_Accuracy: 0.9799\n",
            "Epoch 6/10\n",
            "9466/9466 [==============================] - 44s 5ms/step - loss: 7.1586e-04 - Accuracy: 0.9850 - val_loss: 8.8651e-04 - val_Accuracy: 0.9807\n",
            "Epoch 7/10\n",
            "9466/9466 [==============================] - 45s 5ms/step - loss: 6.4885e-04 - Accuracy: 0.9863 - val_loss: 8.4884e-04 - val_Accuracy: 0.9814\n",
            "Epoch 8/10\n",
            "9466/9466 [==============================] - 45s 5ms/step - loss: 5.9532e-04 - Accuracy: 0.9877 - val_loss: 8.1468e-04 - val_Accuracy: 0.9827\n",
            "Epoch 9/10\n",
            "9466/9466 [==============================] - 45s 5ms/step - loss: 5.4071e-04 - Accuracy: 0.9889 - val_loss: 8.0654e-04 - val_Accuracy: 0.9827\n",
            "Epoch 10/10\n",
            "9466/9466 [==============================] - 48s 5ms/step - loss: 5.0426e-04 - Accuracy: 0.9897 - val_loss: 7.7187e-04 - val_Accuracy: 0.9830\n",
            "3931/3931 [==============================] - 8s 2ms/step - loss: 7.6004e-04 - Accuracy: 0.9838\n",
            "Test Loss: 0.0007600419921800494, Test Accuracy: 0.9838281273841858\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Build Training Report:\n",
        "\n",
        "from datetime import datetime\n",
        "\n",
        "now = datetime.now()\n",
        "\n",
        "current_date = now.strftime(\"%Y-%m-%d\")\n",
        "current_hour = now.hour\n",
        "current_minute = now.minute\n",
        "\n",
        "training_summary = f\"Report Time: {current_date} {current_hour:02d}:{current_minute:02d}\\n\"\n",
        "training_summary += f\"model type: {model_type}\\n\"\n",
        "training_summary += f\"max word length: {max_word_length}\\n\"\n",
        "training_summary += \"\\nHyper-parameters:\\n\"\n",
        "for key, value in hyper_param.items():\n",
        "  training_summary += f\"{key}: {value}\\n\"\n",
        "\n",
        "training_summary += \"\\nArchitechture:\\n\"\n",
        "\n",
        "string =\"1 layer: reshpaing layer\\n\"\n",
        "i = 0\n",
        "for layer in mlp_model.layers:\n",
        "  if isinstance(layer, layers.Dense):\n",
        "    i+=1\n",
        "    mlp_model.layers[i].units\n",
        "    tmp = f\"{i+1} layer: {mlp_model.layers[i].units} units\\n\"\n",
        "    string += tmp\n",
        "string +=\"7 layer: reshpaing layer\\n\"\n",
        "training_summary += string\n",
        "training_summary += \"\\nModel score:\\n\"\n",
        "training_summary += f'Test Loss: {loss:.5f}, Test Accuracy: {accuracy:.2%}\\n'\n",
        "training_summary += \"\\nTraining logs:\\n\"\n",
        "training_summary += str(mlp_model_logs.history)\n",
        "print(training_summary)\n",
        "\n",
        "with open(f'training_summary_{current_date} {current_hour:02d}:{current_minute:02d}.txt', 'w') as f:\n",
        "    f.write(training_summary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PVUpxVR3GSJX",
        "outputId": "add09efb-52ee-4883-de03-5a6b8bd06c18"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Report Time: 2024-03-25 12:18\n",
            "model type: third_char\n",
            "max word length: 8\n",
            "\n",
            "Hyper-parameters:\n",
            "num_epochs: 10\n",
            "loss_func: mean_squared_error\n",
            "lr: 0.001\n",
            "batch_size: 64\n",
            "test_size: 0.15\n",
            "activation_func: relu\n",
            "output_activation: linear\n",
            "validation_split: 0.15\n",
            "random_state: 42\n",
            "\n",
            "Architechture:\n",
            "1 layer: reshpaing layer\n",
            "2 layer: 256 units\n",
            "3 layer: 128 units\n",
            "4 layer: 64 units\n",
            "5 layer: 32 units\n",
            "6 layer: 36 units\n",
            "7 layer: reshpaing layer\n",
            "\n",
            "Model score:\n",
            "Test Loss: 0.00076, Test Accuracy: 98.38%\n",
            "\n",
            "Training logs:\n",
            "{'loss': [0.00394314294680953, 0.0017324592918157578, 0.001142406719736755, 0.0009365206933580339, 0.000802602618932724, 0.0007158611551858485, 0.0006488523213192821, 0.0005953171639703214, 0.0005407070857472718, 0.0005042597185820341], 'Accuracy': [0.9046512842178345, 0.9601590037345886, 0.9753568768501282, 0.9799391627311707, 0.9830028414726257, 0.9850480556488037, 0.9863207340240479, 0.9876644015312195, 0.9889255166053772, 0.9897195100784302], 'val_loss': [0.0025602017994970083, 0.0014148243935778737, 0.001157670863904059, 0.0010173155460506678, 0.000934369454625994, 0.000886505120433867, 0.0008488422026857734, 0.0008146768086589873, 0.0008065401343628764, 0.0007718708366155624], 'val_Accuracy': [0.9289389252662659, 0.9690855741500854, 0.974492073059082, 0.977541446685791, 0.9799453616142273, 0.980749785900116, 0.9814045429229736, 0.9826673269271851, 0.9826579689979553, 0.9829947352409363]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# save model\n",
        "\n",
        "import pickle\n",
        "\n",
        "with open(f'mlp_{model_type}_{current_date} {current_hour:02d}:{current_minute:02d}.pkl', 'wb') as f:\n",
        "    pickle.dump(mlp_model, f)"
      ],
      "metadata": {
        "id": "580a4KOncMZ4"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# download all files\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "files.download(f'/content/mlp_{model_type}_{current_date} {current_hour:02d}:{current_minute:02d}.pkl')\n",
        "\n",
        "files.download(f'/content/training_summary_{current_date} {current_hour:02d}:{current_minute:02d}.txt')\n",
        "\n",
        "files.download('/content/word-root-table_side.xlsx')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "Wn2z_FTcZg_y",
        "outputId": "03575d4c-a5bf-40b0-b232-cb9803243a44"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_669b0724-c529-4c7d-8df8-92e1b5783091\", \"mlp_third_char_2024-03-25 12:18.pkl\", 1460699)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_222cf030-b593-4497-a99d-b826ecbcb145\", \"training_summary_2024-03-25 12:18.txt\", 1401)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_4d367336-c5c2-4411-b345-dd64ce7629fc\", \"word-root-table_side.xlsx\", 1187301)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}